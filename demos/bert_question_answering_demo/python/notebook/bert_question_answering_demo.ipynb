{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wanted-premises",
   "metadata": {},
   "source": [
    "# BERT Question Answering Demo\n",
    "\n",
    "This notebooks demonstrates a Question Answering demo application that uses a SQuAD-tuned BERT model from [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/intel/index.md#question-answering). \n",
    "See `bert_notebook_utils.py` in the same folder as this notebook for the source code to load the model and perform inference. \n",
    "\n",
    "The demo notebook loads a BERT network to [OpenVINO](https://github.com/openvinotoolkit/openvino) Inference Engine. It also fetches data from a user-provided url to populate the \"context\" text.\n",
    "The text is then used to search answers for user-provided questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-attendance",
   "metadata": {},
   "source": [
    "## Settings and Imports\n",
    "\n",
    "Change the `input_url` to change the context of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "from bert_notebook_utils import BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_url = \"https://en.wikipedia.org/wiki/Bert_(Sesame_Street)\"\n",
    "\n",
    "# Other settings (only change this if you know what you are doing!)\n",
    "model_name = \"bert-small-uncased-whole-word-masking-squad-0001\"\n",
    "device = \"CPU\"\n",
    "reshape = False  # Try to reshape the sequence length to the input context + max question len (to improve the speed)\n",
    "model_squad_ver = \"1.2\"  # SQuAD version used for model fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file and directory paths for model. By default, this demo notebook downloads all BERT models from the Open Model Zoo \n",
    "# and stores them in the current directory. Adjust these settings if you want to change this.\n",
    "open_model_zoo_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(os.curdir)))))\n",
    "vocab_file = os.path.join(open_model_zoo_path, \"models\", \"intel\", model_name, \"vocab.txt\")  # vocab file for all BERT models\n",
    "base_model_dir = os.curdir  # Models will be downloaded into the `intel` folder in this directory\n",
    "omz_cache_dir = os.path.expanduser(\"~/open_model_zoo_cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-gazette",
   "metadata": {},
   "source": [
    "## Download BERT models\n",
    "\n",
    "Download BERT models from Open Model Zoo with the Model Downloader. Models are downloaded to `base_model_dir`, which is set to the current directory by default. Open Model Zoo caches the downloaded models in `omz_cache_dir`. By default this is set to `open_model_zoo_cache` in the home directory (`/home/username` on Linux, `c:\\Users\\username` on Windows). If you want to modify these defaults, change the settings in the previous cell. \n",
    "\n",
    "Supported models from the Open Model Zoo are:\n",
    "\n",
    "* bert-large-uncased-whole-word-masking-squad-0001\n",
    "* bert-large-uncased-whole-word-masking-squad-int8-0001\n",
    "* bert-small-uncased-whole-word-masking-squad-0001\n",
    "* bert-small-uncased-whole-word-masking-squad-0002\n",
    "* bert-small-uncased-whole-word-masking-squad-int8-0002\n",
    "\n",
    "See the [Open Model Zoo documentation](https://github.com/openvinotoolkit/open_model_zoo/blob/master/tools/downloader/README.md) for more information on the Model Downloader and [Open Model Zoo Models](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/intel/index.md#question-answering) for information about the models.\n",
    "\n",
    "The code in the next cell downloads the \"small\" models from Open Model Zoo. Change `downloader_model_name` to `\"bert*\"` to download all BERT models, or to a specific model name, for example `bert-large-uncased-whole-word-masking-squad-0001` to download only that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader_model_name = \"bert-small*\"\n",
    "downloader_command = os.path.join(open_model_zoo_path, \"tools\", \"downloader\", \"downloader.py\")\n",
    "subprocess.run([\"python\", downloader_command, \"--output_dir\", base_model_dir, \"--jobs\", \"4\", \"--cache_dir\", omz_cache_dir, \"--precision\", \"FP16,FP16-INT8\", \"--name\", downloader_model_name], shell=False, check=False, capture_output=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-namibia",
   "metadata": {},
   "source": [
    "## Setup BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BERT(input_url, vocab_file, model_name, base_model_dir, reshape=reshape, device=device, model_squad_ver=model_squad_ver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-rendering",
   "metadata": {},
   "source": [
    "## Ask questions!\n",
    "\n",
    "The BERT model returns the answer, a score (the higher the score, the more confident the model is), and the context that was used to find the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.ask(\"What is BERT?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-assessment",
   "metadata": {},
   "source": [
    "# OPTIONAL\n",
    "\n",
    "The functions above are all you need to get started with a BERT model from the Open Model Zoo. If you want to experiment more, the following cells have some suggestions. \n",
    "\n",
    "## Change the input URL and ask more questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.set_input_url(\"https://en.wikipedia.org/wiki/BERT_(language_model)\")\n",
    "bert.ask([\"What is BERT?\", \"Who made BERT?\", \"What prize did BERT win?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-devices",
   "metadata": {},
   "source": [
    "If you just want to see the answers, you can hide the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.ask(\"What is BERT?\", show_context=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-photography",
   "metadata": {},
   "source": [
    "## Change the BERT model\n",
    "\n",
    "Select a model name from these models that you download in the *Download BERT models* section. Use `bert.set_model_name()` to set the name of the model you want to try. Note that the models with `large` in the name require more than 2GB of memory and may not run on Binder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.set_model_name(\"bert-small-uncased-whole-word-masking-squad-int8-0002\")\n",
    "bert.ask([\"What is BERT?\", \"Who made BERT?\", \"What prize did BERT win?\"])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
