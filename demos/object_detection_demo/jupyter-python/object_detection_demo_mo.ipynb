{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hawaiian-valley",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 3,
        "row": 0,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "# Open Model Zoo Object Detection Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-traveler",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 3,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": [
     "hide",
     "hidden"
    ]
   },
   "source": [
    "This demo showcases Object Detection on Open Model Zoo models with Async API.\n",
    "\n",
    "Async API usage can improve the overall frame-rate of the application, because rather than wait for inference to complete, the app can continue doing things on the host, while accelerator is busy.\n",
    "\n",
    "Other demo objectives are:\n",
    "\n",
    "* Video as input support via OpenCV\\*\n",
    "* Visualization of the resulting bounding boxes\n",
    "* Comparison of different Open Model Zoo models\n",
    "\n",
    "See the [Python Object Detection Async Demo](../python/) for more details about the Async API, and the [Optimization Guide](https://docs.openvinotoolkit.org/latest/_docs_optimization_guide_dldt_optimization_guide.html) for more information on optimizing models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-reporter",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-warning\" style=\"color:black\"><i>\n",
    "<b>Note: </b>Binder has limited resources. If you run this notebook in Binder, it may suddenly stop. You can reload the page and try a different model, or run the notebook on your own computer. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-charter",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 5,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": [
     "hide",
     "hidden"
    ]
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-furniture",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "\n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import Layout, fixed, interact, interact_manual\n",
    "from openvino.inference_engine import IECore\n",
    "\n",
    "from detection_utils import (\n",
    "    ColorPalette,\n",
    "    download_video,\n",
    "    draw_detections,\n",
    "    get_model,\n",
    "    put_highlighted_text,\n",
    ")\n",
    "\n",
    "open_model_zoo_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(os.curdir))))\n",
    "\n",
    "\n",
    "sys.path.append(os.path.join(open_model_zoo_path, \"demos\", \"common\", \"python\"))\n",
    "\n",
    "from pipelines import AsyncPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-investigator",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 23,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": [
     "hide",
     "hidden"
    ]
   },
   "source": [
    "## Settings\n",
    "\n",
    "Set the file and directory paths. The default settings expect that the models are located in `open_model_zoo_models` in your `$HOME` directory, typically `c:\\users\\username` or `/home/username`. You can change this by setting the `base_model_dir` variable to another directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-jumping",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "base_model_dir = os.path.expanduser(\"~/open_model_zoo_models\")\n",
    "precision = \"FP16\"\n",
    "num_infer_requests = 3\n",
    "loop = False\n",
    "prob_threshold = 0.5\n",
    "utilization_monitors = \"\"\n",
    "device = \"CPU\"\n",
    "\n",
    "palette = ColorPalette(100)\n",
    "font_scale = 1\n",
    "thickness = 2\n",
    "\n",
    "DOWNLOAD_MODELS = True\n",
    "CONVERT_MODELS = False\n",
    "\n",
    "omz_cache_dir = os.path.expanduser(\"~\")\n",
    "\n",
    "# The settings below are only required if you want to use the Model Converter to convert models to OpenVINO IR format.\n",
    "# You can use this demo with models that are already downloaded in IR format, so use of the model optimizer is optional.\n",
    "\n",
    "# The path to the Model Optimizer is required if models need to be converted to IR. The paths below should work for default installations of\n",
    "# the Intel Distribution of OpenVINO Toolkit https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html\n",
    "# Adjust them if you installed OpenVINO in a different location.\n",
    "# Note that you also need to install the Model Optimizer prerequisites. See the documentation for your OS at\n",
    "# https://docs.openvinotoolkit.org/latest/installation_guides.html\n",
    "if CONVERT_MODELS:\n",
    "    if sys.platform.startswith(\"win\"):\n",
    "        model_optimizer_path = (\n",
    "            r\"C:\\Program Files (x86)\\intel\\openvino_2021\\deployment_tools\\model_optimizer\\mo.py\"  # Windows\n",
    "        )\n",
    "    else:\n",
    "        model_optimizer_path = \"/opt/intel/openvino_2021/deployment_tools/model_optimizer/mo.py\"  # Linux/MacOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-nomination",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "## Download Models and convert them to IR format\n",
    "\n",
    "The [Model Downloader](https://github.com/openvinotoolkit/open_model_zoo/blob/master/tools/downloader/README.md) downloads models from the Open Model Zoo. Models that are not in OpenVINO IR format are converted to this format by the Model Converter. \n",
    "\n",
    "The [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/) models that are compatible with this demo are listed in the file *models.lst* in the same folder as this notebook. By default all these models are downloaded, with the `--list=models.lst` argument for the Model Downloader. You can choose to download a specific model by using `--name=model_name` instead of `--list=models.lst`. If you already have downloaded Open Zoo Models, you can set the `base_model_dir` variable in the *Settings* cell to the folder that contains your models (this should be a folder with subfolders `intel` and `public`) and set `DOWNLOAD_MODELS` to `False`.\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"color:black\"><i>\n",
    "<b>Note: </b>It will take a while to download and convert all the models. </div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_MODELS:\n",
    "    downloader_command = os.path.join(open_model_zoo_path, \"tools\", \"downloader\", \"downloader.py\")\n",
    "    download_result = subprocess.run(\n",
    "        [\n",
    "            \"python\",\n",
    "            downloader_command,\n",
    "            \"--output_dir\",\n",
    "            base_model_dir,\n",
    "            \"--jobs\",\n",
    "            \"4\",\n",
    "            \"--cache_dir\",\n",
    "            omz_cache_dir,\n",
    "            \"--precision\",\n",
    "            precision,\n",
    "            \"--list\",\n",
    "            \"models.lst\",\n",
    "        ],\n",
    "        shell=False,\n",
    "        check=False,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True,\n",
    "    )\n",
    "#     if download_result.returncode == 0:\n",
    "#         print(\n",
    "#             \"Downloading models succeeded. You can set `DOWNLOAD_MODELS=False` to save some time when you run this notebook again.\"\n",
    "#         )\n",
    "#     else:\n",
    "#         print(f\"Downloading models failed. The error message is: {download_result.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the models that are not in IR format to IR\n",
    "if CONVERT_MODELS:\n",
    "    converter_command = os.path.join(open_model_zoo_path, \"tools\", \"downloader\", \"converter.py\")\n",
    "    converter_result = subprocess.run(\n",
    "        [\n",
    "            \"python\",\n",
    "            converter_command,\n",
    "            \"--download_dir\",\n",
    "            base_model_dir,\n",
    "            \"--list\",\n",
    "            \"models.lst\",\n",
    "            \"--precisions\",\n",
    "            precision,\n",
    "            \"--mo\",\n",
    "            model_optimizer_path,\n",
    "        ],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        capture_output=False,\n",
    "        shell=False,\n",
    "    )\n",
    "    if converter_result.returncode == 0:\n",
    "        print(\"Converting models succeeded.\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"There were some error messages while converting the models. Check `converter_result.stderr` for more details.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-nickel",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 25,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": [
     "hide"
    ]
   },
   "source": [
    "### Get model info\n",
    "\n",
    "The Info Dumper returns information for the Open Model Zoo models. It returns a list of dictionaries with the model name, description, framework, license url, precisions, task type, and the subdirectory for the downloaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-blend",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "info_command = os.path.join(open_model_zoo_path, \"tools\", \"downloader\", \"info_dumper.py\")\n",
    "info_result = subprocess.run(\n",
    "    [\n",
    "        \"python\",\n",
    "        info_command,\n",
    "        \"--list\",\n",
    "        \"models.lst\",\n",
    "    ],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    "    capture_output=False,\n",
    "    shell=False,\n",
    "    text=True,\n",
    ")\n",
    "info = json.loads(info_result.stdout)\n",
    "\n",
    "model_names = [model[\"name\"] for model in info if \"intel\" in model[\"subdirectory\"]]\n",
    "# model_names = [model[\"name\"] for model in info ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-command",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 27,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Show an example of the information that the Info Dumper returns\n",
    "info[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-generator",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 29,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": [
     "hide"
    ]
   },
   "source": [
    "The `models.lst` file lists the models that are supported by this demo, sorted by architecture. The model names can contain wildcard. For example, `face-detection-????` means that the demo supports all models with a name that starts with `face-detection-` followed by four digits. \n",
    "\n",
    "We create a `model_architectures` dictionary that maps the model names given by the Info Dumper, to an architecture given by `models.lst`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-boston",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "model_architectures = {}\n",
    "modellist = open(\"models.lst\").read().splitlines()\n",
    "\n",
    "for line in modellist[1:]:\n",
    "    if line.startswith(\"# For\"):\n",
    "        _, architecture = line.split(\"=\")\n",
    "    else:\n",
    "        model_architectures[line] = architecture\n",
    "        for modelname in model_names:\n",
    "            modelpattern = re.search(line.replace(\"?\", \"[0-9]\"), modelname)\n",
    "            if modelpattern:\n",
    "                model_architectures[modelpattern.group(0)] = architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-cooking",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 31,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": [
     "hide"
    ]
   },
   "source": [
    "## Create inference functions\n",
    "\n",
    "The `do_inference_on_video` function performs the inference of a model on a specific video. The helper function `process_results` add the time to the result from the pipeline, so that the inference speed can be computed. The function opens the video file given by `input_filename` with OpenCV's `VideoCapture`. It reads the frames sequentially, `jump_frames` frames at a time. If `jump_frames = 1` all frames will be read. By default `jump_frames=10` which means that every tenth frame will be read. While there are new frames, the code:\n",
    "\n",
    "* Checks if there are results from the pipeline. If there are, it records the time, and adds the result to the list of results\n",
    "* Checks if the pipeline is ready. If it is, it sees if there is a new frame. \n",
    "  * If there is a new frame (we have not reached the end of the video), the frame is read, and sent to the detector pipeline for inference. \n",
    "  * If there are no more frames, the video is closed\n",
    "\n",
    "At the end of the function, we wait until the detector is finished, and add the final results to the list of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-people",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "jump_frames = 10\n",
    "\n",
    "\n",
    "def do_inference_on_video(detector_pipeline, input_filename):\n",
    "    resultlist = []\n",
    "    next_frame_id = 0\n",
    "    next_frame_id_to_show = 0\n",
    "    overall_start_time = perf_counter()\n",
    "\n",
    "    def process_results(results):\n",
    "        \"\"\"Helper function to add inference time to results\"\"\"\n",
    "        outputs, meta = results\n",
    "        meta[\"end_time\"] = perf_counter()\n",
    "        meta[\"overall_start_time\"] = overall_start_time\n",
    "        return outputs, meta\n",
    "\n",
    "    cap = cv2.VideoCapture(input_filename)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, next_frame_id)\n",
    "        if detector_pipeline.callback_exceptions:\n",
    "            raise detector_pipeline.callback_exceptions[0]\n",
    "\n",
    "        # Process all completed requests\n",
    "        results = detector_pipeline.get_result(next_frame_id_to_show)\n",
    "        if results:\n",
    "            resultlist.append(process_results(results))\n",
    "            next_frame_id_to_show += jump_frames\n",
    "\n",
    "        if detector_pipeline.is_ready():\n",
    "            # Get new image/frame\n",
    "            start_time = perf_counter()\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                cap.release()\n",
    "                continue\n",
    "\n",
    "            # Submit for inference\n",
    "            detector_pipeline.submit_data(frame, next_frame_id, {\"frame\": frame, \"start_time\": start_time})\n",
    "            next_frame_id += jump_frames\n",
    "\n",
    "        else:\n",
    "            # Wait for empty request\n",
    "            detector_pipeline.await_any()\n",
    "        # Process completed requests\n",
    "\n",
    "    detector_pipeline.await_all()\n",
    "\n",
    "    while detector_pipeline.has_completed_request():\n",
    "        results = detector_pipeline.get_result(next_frame_id_to_show)\n",
    "        if results:\n",
    "            resultlist.append(process_results(results))\n",
    "            next_frame_id_to_show += jump_frames\n",
    "\n",
    "    return resultlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-christmas",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def get_results_for_model(modelname, num_threads, num_streams, num_requests):\n",
    "    input_filename = get_input_filename()\n",
    "    model_info = [item for item in info if item[\"name\"] == modelname][0]\n",
    "    model_xml = os.path.join(base_model_dir, model_info[\"subdirectory\"], precision, modelname + \".xml\")\n",
    "    resultvideos = []\n",
    "    architecture_type = model_architectures[modelname]\n",
    "    ie = IECore()\n",
    "\n",
    "    model = get_model(ie, model=Path(model_xml), architecture_type=architecture_type, labels=None)\n",
    "    plugin_config = {\n",
    "        \"CPU_THREADS_NUM\": f\"{num_threads}\",\n",
    "        \"CPU_THROUGHPUT_STREAMS\": f\"{num_streams}\",\n",
    "    }\n",
    "    detector_pipeline = AsyncPipeline(ie, model, plugin_config, device=\"CPU\", max_num_requests=num_requests)\n",
    "    print(\n",
    "        f\"Starting inference. Model: {modelname}, video: {input_filename},  threads: {num_threads}, streams: {num_streams}, max_num_requests: {num_requests}\"\n",
    "    )\n",
    "    start_time = perf_counter()\n",
    "    result = do_inference_on_video(detector_pipeline, input_filename)\n",
    "    end_time = perf_counter()\n",
    "\n",
    "    has_landmarks = architecture_type == \"retina\"\n",
    "\n",
    "    resultvideo = make_result_videos(result, has_landmarks)\n",
    "    fps = len(resultvideo) / (end_time - start_time)\n",
    "\n",
    "    return resultvideo, fps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-iceland",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 33,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": [
     "hide"
    ]
   },
   "source": [
    "The `make_result_videos` function takes the output of the `do_inference_on_video` function and returns a list of videoframes with detection boxes drawn on the frame, as well as the fps and latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-hometown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def make_result_videos(resultlist, has_landmarks):\n",
    "    framelist = list()\n",
    "\n",
    "    for i, (objects, meta) in enumerate(resultlist):\n",
    "        start_time = meta[\"start_time\"]\n",
    "        overall_start_time = meta[\"overall_start_time\"]\n",
    "        end_time = meta[\"end_time\"]\n",
    "        latency = (end_time - start_time) * 1000\n",
    "        fps = (i + 1) / (end_time - overall_start_time)\n",
    "\n",
    "        frame = meta[\"frame\"]\n",
    "        frame = draw_detections(\n",
    "            frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB),\n",
    "            detections=objects,\n",
    "            palette=palette,\n",
    "            labels=None,\n",
    "            threshold=prob_threshold,\n",
    "            draw_landmarks=has_landmarks,\n",
    "        )\n",
    "        put_highlighted_text(\n",
    "            frame,\n",
    "            \"Latency: {:.1f} ms\".format(latency),\n",
    "            (20, 30),\n",
    "            cv2.FONT_HERSHEY_COMPLEX,\n",
    "            font_scale,\n",
    "            palette[0],\n",
    "            thickness,\n",
    "        )\n",
    "        put_highlighted_text(\n",
    "            frame,\n",
    "            \"FPS: {:.1f}\".format(fps),\n",
    "            (20, 60),\n",
    "            cv2.FONT_HERSHEY_COMPLEX,\n",
    "            font_scale,\n",
    "            palette[0],\n",
    "            thickness,\n",
    "        )\n",
    "\n",
    "        framelist.append(frame)\n",
    "    return framelist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-accreditation",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 35,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": [
     "hide"
    ]
   },
   "source": [
    "## Create widgets\n",
    "\n",
    "This demo works with a variety of [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/) models and allows you to use your own video.  We create widgets with [IPywidgets](https://github.com/jupyter-widgets/ipywidgets) to easily select a model and choose a video from your PC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-tongue",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 37,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "## Download or upload a video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-receiver",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 39,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "### Option 1: Download a sample video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-piece",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "sample_video_base_url = \"https://github.com/intel-iot-devkit/sample-videos/raw/master\"\n",
    "sample_video_filenames = open(\"sample_videos.lst\").read().splitlines()\n",
    "sample_video_list = [(fn[:-4], os.path.join(sample_video_base_url, fn)) for fn in sample_video_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-might",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 41,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "sample_video = widgets.Dropdown(options=sample_video_list, index=12)\n",
    "sample_video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-arrest",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 43,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "### Option 2: Upload your own video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-artwork",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 45,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "uploader = widgets.FileUpload(multiple=False)\n",
    "uploader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-alert",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 47,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": [
     "hide"
    ]
   },
   "source": [
    "`get_input_filename` checks if a video was uploaded. If so, it returns the filename of that video. If not, it returns the selected sample video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-drunk",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def get_input_filename():\n",
    "    \"\"\"\n",
    "    If a video is uploaded, process and save the uploaded video. If not, download the selected sample video.\n",
    "    \n",
    "    :return: the filename of the uploaded video if available, or the filename of the selected sample video.\n",
    "    \"\"\"\n",
    "    if len(uploader.value) > 0:\n",
    "        uploaded_filename = next(iter(uploader.value))\n",
    "        content = uploader.value[uploaded_filename][\"content\"]\n",
    "        with open(uploaded_filename, \"wb\") as f:\n",
    "            f.write(content)\n",
    "        input_filename = uploaded_filename\n",
    "    else:\n",
    "        input_filename = os.path.basename(sample_video.value)\n",
    "        if not os.path.exists(input_filename):\n",
    "            download_video(sample_video.value)\n",
    "\n",
    "    return input_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-findings",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 50,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Detection results of one model, drawn on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-protein",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 52,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": false,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "interact_inference = interact_manual.options(manual_name=\"Do inference\")\n",
    "\n",
    "\n",
    "@interact_inference\n",
    "def show_results_on_model(model=model_names, num_threads=(0, 8), num_streams=(0, 8), num_requests=(0, 10)):\n",
    "    \"\"\"\n",
    "    Perform inference and display results for the selected model, with specified number of threads, streams and max number of requests.\n",
    "    \"\"\"\n",
    "    resultvideo, fps = get_results_for_model(model, num_threads, num_streams, num_requests)\n",
    "    for item in resultvideo:\n",
    "        clear_output(wait=True)\n",
    "        plt.imshow(item)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "    print(\n",
    "        f\"Finished inference. Model: {model},  threads: {num_threads}, streams: {num_streams}, max_num_requests: {num_requests}. FPS: {fps:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-drink",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 54,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Detection results of multiple models\n",
    "\n",
    "Perform inference on up to four selected models. Show results on three random frames by clicking on the *Show frames* button after inference is complete. Click the button again to show different frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-practitioner",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "select_model_widget = widgets.SelectMultiple(\n",
    "    description=\"Models\",\n",
    "    options=model_names,\n",
    "    index=[2, 5, 7],\n",
    "    rows=32,\n",
    "    layout=Layout(display=\"flex\", flex_flow=\"column\"),\n",
    "    disabled=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-journey",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 58,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "@interact_inference(modelnames=select_model_widget)\n",
    "def show_inference_multiple_models(modelnames, num_threads=(0, 8), num_streams=(0, 8), num_requests=(0, 10)):\n",
    "    \"\"\"\n",
    "    Perform inference for the selected models. The results are put in a global variable `inference_results_multiple_models`\n",
    "    so that they can be accessed from other functions.\n",
    "    \"\"\"\n",
    "    global g_inference_results_multiple_models\n",
    "    resultvideos = []\n",
    "    for i, modelname in enumerate(modelnames):\n",
    "        resultvideo, fps = get_results_for_model(modelname, num_threads, num_streams, num_requests)\n",
    "        g_inference_results_multiple_models.append(resultvideo)\n",
    "        print(f\"--- Finished: FPS: {fps:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-campaign",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 60,
        "width": 12
       },
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "@interact_manual.options(manual_name=\"Show frames\")\n",
    "def show_random_frames():\n",
    "    global g_inference_results_multiple_models\n",
    "    try:\n",
    "        fig, ax = plt.subplots(3, len(select_model_widget.value), figsize=(25, 15), squeeze=False)\n",
    "\n",
    "        indices = random.choices(range(len(g_inference_results_multiple_models[0])), k=3)\n",
    "        for i in range(len(g_inference_results_multiple_models)):\n",
    "            modelname = select_model_widget.value[i]\n",
    "            resultvideo = resultvideos[i]\n",
    "\n",
    "            for j, framenr in enumerate(indices):\n",
    "                ax[j, i].imshow(resultvideo[framenr])\n",
    "                ax[0, i].set_title(modelname)\n",
    "        for a in ax.ravel():\n",
    "            a.axis(\"off\")\n",
    "    except NameError:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "default_view",
    "version": 1,
    "views": {
     "default_view": {
      "cellMargin": 10,
      "defaultCellHeight": 40,
      "maxColumns": 12,
      "name": "active_view",
      "type": "grid"
     },
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 60,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
